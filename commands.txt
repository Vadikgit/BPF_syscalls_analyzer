make map_extractor
make analyzer
make read_stat
make read_map

sudo ./analyzer -start
sudo ./read_map 1000 10
sudo ./analyser -stop

sudo bpftool map

sudo ./analyzer -start -pid 5511

sudo cat /sys/kernel/debug/tracing/trace_pipe


docker run --rm --name linux -it ubuntu:18.04 /bin/bash


docker top naughty_mccarthy

sudo apt-get install iputils-ping

apt-get update

pstree -p

docker exec -ti linux sh

apt-get install psmisc


from proc:
 cat 6141/status | grep -i NSpid

uname -r

stat --printf='%d %i' /proc/self/ns/pid
stat /proc/self/ns/pid


docker run --name linux -it --rm ubuntu:latest /bin/bash
docker run -v shared_vol:/home/ubuntu/vol --name linux -it --rm ubuntu:18.04 /bin/bash
docker run -v "/home/vadim/Документы/prog/bpf_process_tree_builder/shared_vol:/home/ubuntu/vol" --name linux -it --rm ubuntu:latest /bin/bash
docker run --name py_app -it --rm vadksen01/python_app
docker inspect -f '{{.State.Pid}}' <container id>

pstree -ps -U 12655



sudo ./tree_extractor 6 7 8

5816
sudo bpftool map update name to_track_pid key 0 0 0 0 value 184 22 0 0
sudo bpftool map dump name SeqNums

printf "%x\n" 5816
16b8

6737
sudo bpftool map update name to_track_pid key 0 0 0 0 value hex 51 1a 0 0


source script.sh
recProcedure 0


sudo ./read_map 17 "1 2 3 4" 930 20

bash -c "source script.sh; ls; ping ya.ru -c 1; recProcedure $i; exit"
bash -c "source script.sh; ls; ps; recProcedure $i; exit"



/usr/bin/time --format "%U %e %S" dd if=/dev/sda3 of=/dev/null bs=4000B count=2000000
time dd if=/dev/sda of=/dev/null bs=4096B count=800000

mapfile -t my_array < <( { /usr/bin/time --format "%U\n%e\n%S\n" dd if=/dev/sda3 of=/dev/null bs=4000B count=100000 status=none; } 2>&1 )





docker pull apache/kafka:3.8.0
docker run -p 9092:9092 apache/kafka:3.8.0
docker ps

docker exec -it -w /opt/kafka/bin funny_satoshi sh


./kafka-topics.sh --create --topic test --bootstrap-server 127.0.0.1:9092

./kafka-topics.sh --delete --topic test --bootstrap-server localhost:9092


./kafka-console-consumer.sh --topic test --bootstrap-server 127.0.0.1:9092 \
--from-beginning \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.IntegerDeserializer"

./kafka-console-consumer.sh --topic test --bootstrap-server 127.0.0.1:9092 \
--from-beginning \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " 

./kafka-console-consumer.sh --topic test --bootstrap-server 127.0.0.1:9092 \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.IntegerDeserializer"


./kafka-console-producer.sh --topic user-statuses-topic --bootstrap-server 127.0.0.1:9092

./kafka-console-consumer.sh --topic user-statuses-topic --from-beginning --bootstrap-server 127.0.0.1:9092


./kafka-console-consumer.sh --topic pulse --bootstrap-server 127.0.0.1:9092 \
--from-beginning \
--value-deserializer "org.apache.kafka.common.serialization.IntegerDeserializer"


./kafka-console-consumer.sh --topic pulse --bootstrap-server 127.0.0.1:9092 \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.LongDeserializer" \
--value-deserializer "org.apache.kafka.common.serialization.IntegerDeserializer"

./kafka-console-consumer.sh --topic pulse_for_10min --bootstrap-server 127.0.0.1:9092 \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.LongDeserializer" \
--value-deserializer "org.apache.kafka.common.serialization.DoubleDeserializer"


./kafka-console-consumer.sh --topic location --bootstrap-server 127.0.0.1:9092 \
--from-beginning \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.LongDeserializer" \
--value-deserializer "org.apache.kafka.common.serialization.BytesDeserializer"


./kafka-console-consumer.sh --topic average_speed_vector --bootstrap-server 127.0.0.1:9092 \
--from-beginning \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.LongDeserializer" \
--value-deserializer "org.apache.kafka.common.serialization.BytesDeserializer"



./kafka-console-consumer.sh --topic average_speed_vector --bootstrap-server 127.0.0.1:9092 \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.LongDeserializer"



./kafka-console-consumer.sh --topic motion_point --bootstrap-server 127.0.0.1:9092 \
--property print.key=true \
--property print.value=true \
--property key.separator=" : " \
--key-deserializer "org.apache.kafka.common.serialization.LongDeserializer"


./kafka-console-consumer.sh --topic most_filled_sectors --bootstrap-server 127.0.0.1:9092

./kafka-console-producer.sh  --topic user-statuses-topic --bootstrap-server 127.0.0.1:9092


/home/vadim/python3.7/bin/python tcp_server_with_kafka_producer.py


flink:
cd flink/flink-2.0-preview1

./bin/start-cluster.sh

./bin/flink run examples/streaming/WordCount.jar --input "/home/vadim/stream_data_analysis/flink/input.txt" --output "/home/vadim/stream_data_analysis/flink/output.txt"

./flink run /home/vadim/stream_data_analysis/flink/untitled/trying2/build/libs/trying2-0.1-SNAPSHOT-all.jar
